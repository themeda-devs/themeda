{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from themeda.preproc.chiplets import load_chiplets\n",
    "import glob\n",
    "import pathlib\n",
    "import itertools\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Chips "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_instance_nums = list(range(1,13000,100))\n",
    "\n",
    "chiplets = load_chiplets(\n",
    "    chiplet_dir=pathlib.Path(\"/data/projects/punim1932/Data/chiplets/level4\"),\n",
    "    subset_nums=[\"3\"],\n",
    "    measurement=\"level4\",\n",
    "    subset_instance_nums=subset_instance_nums\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiplet_data=[]\n",
    "for chiplet in chiplets:\n",
    "    chiplet_data.append((chiplet.year,chiplet.data,chiplet.position))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_distributions = {}\n",
    "for year, data, position in chiplet_data:\n",
    "    tfid_distribution = Counter(data.flatten())\n",
    "    if position in position_distributions:\n",
    "        position_distributions[position].append(tfid_distribution)\n",
    "    else:\n",
    "        position_distributions[position] = [tfid_distribution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hypothesis testing for each position\n",
    "failed_hypothesis=0\n",
    "total_hypothesis=0\n",
    "for position, distributions in list(position_distributions.items()):\n",
    "    n_years = len(distributions)\n",
    "    for i in range(n_years - 1):\n",
    "        distribution1 = distributions[i]\n",
    "        distribution2 = distributions[i + 1]\n",
    "\n",
    "        # Create contingency table for chi-square test\n",
    "        contingency_table = []\n",
    "        for tfid in set(distribution1.keys()).union(distribution2.keys()):\n",
    "            count1 = distribution1.get(tfid, 0)\n",
    "            count2 = distribution2.get(tfid, 0)\n",
    "            contingency_table.append([count1, count2])\n",
    "        # Perform chi-square test\n",
    "        chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "\n",
    "        # Compare p-value with significance level\n",
    "        if p_value < alpha:\n",
    "            failed_hypothesis+=1\n",
    "        total_hypothesis+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.94871794871794"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_hypothesis/total_hypothesis * 100 #At 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.94871794871794"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_hypothesis/total_hypothesis * 100 #At 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the significance level for the hypothesis test\n",
    "alpha = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kruskal Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_instance_nums = list(range(1, 13000, 100))\n",
    "\n",
    "chiplets = load_chiplets(\n",
    "    chiplet_dir=pathlib.Path(\"/data/projects/punim1932/Data/chiplets/level4\"),\n",
    "    subset_nums=[\"3\"],\n",
    "    measurement=\"level4\",\n",
    "    subset_instance_nums=subset_instance_nums\n",
    ")\n",
    "\n",
    "chiplet_data = []\n",
    "for chiplet in chiplets:\n",
    "    chiplet_data.append((chiplet.year, chiplet.data, chiplet.position))\n",
    "\n",
    "position_distributions = {}\n",
    "for year, data, position in chiplet_data:\n",
    "    tfid_distribution = Counter(data.flatten())\n",
    "    if position in position_distributions:\n",
    "        position_distributions[position].append(tfid_distribution)\n",
    "    else:\n",
    "        position_distributions[position] = [tfid_distribution]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consecutive Year Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.410256410256412"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# Perform hypothesis testing for each position\n",
    "failed_hypothesis = 0\n",
    "total_hypothesis = 0\n",
    "for position, distributions in list(position_distributions.items()):\n",
    "    n_years = len(distributions)\n",
    "    for i in range(n_years - 1):\n",
    "        distribution1 = distributions[i]\n",
    "        distribution2 = distributions[i + 1]\n",
    "\n",
    "        # Create contingency table for chi-square test\n",
    "        contingency_table = []\n",
    "        unique_tfids = set(distribution1.keys()).union(distribution2.keys())\n",
    "        for tfid in unique_tfids:\n",
    "            percentage1 = distribution1.get(tfid, 0) / sum(distribution1.values())\n",
    "            percentage2 = distribution2.get(tfid, 0) / sum(distribution2.values())\n",
    "            contingency_table.append([percentage1, percentage2])\n",
    "\n",
    "        # Perform chi-square test\n",
    "        chi2, p_value = stats.kruskal(*contingency_table)\n",
    "\n",
    "        # Compare p-value with significance level\n",
    "        if p_value < alpha:\n",
    "            failed_hypothesis += 1\n",
    "        total_hypothesis += 1\n",
    "\n",
    "failed_hypothesis / total_hypothesis * 100  # At alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First and Final Year Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.923076923076923"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# Perform hypothesis testing for each position\n",
    "failed_hypothesis = 0\n",
    "total_hypothesis = 0\n",
    "\n",
    "for position, distributions in list(position_distributions.items()):\n",
    "    distribution1 = distributions[0]  # First year\n",
    "    distribution2 = distributions[-1]  # Final year\n",
    "\n",
    "    # Create contingency table for Kruskal-Wallis test\n",
    "    contingency_table = []\n",
    "    unique_tfids = set(distribution1.keys()).union(distribution2.keys())\n",
    "    for tfid in unique_tfids:\n",
    "        percentage1 = distribution1.get(tfid, 0) / sum(distribution1.values())\n",
    "        percentage2 = distribution2.get(tfid, 0) / sum(distribution2.values())\n",
    "        contingency_table.append([percentage1, percentage2])\n",
    "\n",
    "    # Perform Kruskal-Wallis test\n",
    "    _, p_value = stats.kruskal(*contingency_table)\n",
    "\n",
    "    # Compare p-value with significance level\n",
    "    if p_value < alpha:\n",
    "        failed_hypothesis += 1\n",
    "    total_hypothesis += 1\n",
    "\n",
    "failed_hypothesis / total_hypothesis * 100  # At alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.92307692307693"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "for position, distributions in list(position_distributions.items()):\n",
    "    first_year_distributions = distributions[:5]\n",
    "    last_year_distributions = distributions[-5:]\n",
    "    \n",
    "    mean_distribution1={}\n",
    "    for distribution in first_year_distributions:\n",
    "        for key in dict(distribution):\n",
    "            if key not in mean_distribution1:\n",
    "                mean_distribution1[key]=distribution[key]\n",
    "            else:\n",
    "                mean_distribution1[key]+=distribution[key]\n",
    "    mean_distribution1={key:int(mean_distribution1[key]/5) for key in mean_distribution1}\n",
    "    \n",
    "    mean_distribution2={}\n",
    "    for distribution in last_year_distributions:\n",
    "        for key in dict(distribution):\n",
    "            if key not in mean_distribution2:\n",
    "                mean_distribution2[key]=distribution[key]\n",
    "            else:\n",
    "                mean_distribution2[key]+=distribution[key]\n",
    "    mean_distribution2={key:int(mean_distribution2[key]/5) for key in mean_distribution2}\n",
    "    \n",
    "    # Create contingency table for Kruskal-Wallis test\n",
    "    contingency_table = []\n",
    "    unique_tfids = set(mean_distribution1.keys()).union(mean_distribution2.keys())\n",
    "    for tfid in unique_tfids:\n",
    "        count1 = mean_distribution1.get(tfid, 0)\n",
    "        count2 = mean_distribution2.get(tfid, 0)\n",
    "        contingency_table.append([count1, count2])\n",
    "\n",
    "    # Perform Kruskal-Wallis test\n",
    "    _, p_value = stats.kruskal(*contingency_table)\n",
    "\n",
    "    # Compare p-value with significance level\n",
    "    if p_value < alpha:\n",
    "        failed_hypothesis += 1\n",
    "    total_hypothesis += 1\n",
    "\n",
    "failed_hypothesis / total_hypothesis * 100  # At alpha = 0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "themeda",
   "language": "python",
   "name": "themeda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
